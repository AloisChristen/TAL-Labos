{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger l'archive `UD_French-GSD-withBlankLines.zip` fournie sur Cyberlearn.\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les mots sont dans la colonne 0, et les POS tags dans la colonne 2.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule.\n",
    "print(\"Les mots sont dans la colonne 0, et les POS tags dans la colonne 2.\")\n",
    "url = \"https://universaldependencies.org/u/pos/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token number of test :  10298\n",
      "Token number of dev :  36830\n",
      "Token number of train :  366371\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule\n",
    "def tokens_number(filename):\n",
    "    fd = open(filename, \"r\", encoding=\"utf-8\")\n",
    "    nb_tokens = len(list(filter(None, fd.read().splitlines())))\n",
    "    fd.close()\n",
    "    return nb_tokens\n",
    "\n",
    "print(\"Token number of test : \", tokens_number(\"fr-ud-test.conllu3\"))\n",
    "print(\"Token number of dev : \", tokens_number(\"fr-ud-dev.conllu3\"))\n",
    "print(\"Token number of train : \", tokens_number(\"fr-ud-train.conllu3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.6 sec].\n",
      "Tagged 36830 words at 14143,63 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 1478 sentences and 36830 words, of which 3049 were unknown.\n",
      "Total sentences right: 144 (9,742896%); wrong: 1334 (90,257104%).\n",
      "Total tags right: 32360 (87,863155%); wrong: 4470 (12,136845%).\n",
      "Unknown words right: 2232 (73,204329%); wrong: 817 (26,795671%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model french-ud.tagger -testFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3\" -verboseResults false\n",
    "# Les scores sont : 87.9% sur les tags, 9.7% sur les phrases et 73.2% sur les mots inconnus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.4 sec].\n",
      "Tagged 10298 words at 10349,75 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 416 sentences and 10298 words, of which 697 were unknown.\n",
      "Total sentences right: 54 (12,980769%); wrong: 362 (87,019231%).\n",
      "Total tags right: 8960 (87,007186%); wrong: 1338 (12,992814%).\n",
      "Unknown words right: 487 (69,870875%); wrong: 210 (30,129125%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model french-ud.tagger -testFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3\" -verboseResults false\n",
    "# précision de 87% sur les tags, 13% sur les phrases, 69.9% sur les mots inconnus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiare** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses ci-dessous, en commentaires.\n",
    "# il trouve 36830 mots pour dev, soit la même chose que nous.\n",
    "# il trouve 10298 mots pour test, soit la même chose que nous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "import os\n",
    "propfile =! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger  -genprops\n",
    "filename = \"myFrench-ud.tagger.props\"\n",
    "if(not(os.path.exists(filename))):\n",
    "    fd = open(filename, 'a', encoding='utf-8')\n",
    "    fd.write(\"\\r\\n\".join(propfile))\n",
    "    fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger  -props myFrench-ud.tagger.props -trainFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-train.conllu3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger myFrench-ud.tagger\n",
      "Loading POS tagger from myFrench-ud.tagger ... done [0.5 sec].\n",
      "Tagged 36830 words at 12656,36 words per second.\n",
      "Model myFrench-ud.tagger has xSize=305182, ySize=19, and numFeatures=96503.\n",
      "Results on 1478 sentences and 36830 words, of which 2701 were unknown.\n",
      "Total sentences right: 797 (53,924222%); wrong: 681 (46,075778%).\n",
      "Total tags right: 35674 (96,861254%); wrong: 1156 (3,138746%).\n",
      "Unknown words right: 2398 (88,781933%); wrong: 303 (11,218067%).\n",
      "Loading default properties from tagger myFrench-ud.tagger\n",
      "Loading POS tagger from myFrench-ud.tagger ... done [0.4 sec].\n",
      "Tagged 10298 words at 10267,20 words per second.\n",
      "Model myFrench-ud.tagger has xSize=305182, ySize=19, and numFeatures=96503.\n",
      "Results on 416 sentences and 10298 words, of which 601 were unknown.\n",
      "Total sentences right: 203 (48,798077%); wrong: 213 (51,201923%).\n",
      "Total tags right: 9899 (96,125461%); wrong: 399 (3,874539%).\n",
      "Unknown words right: 517 (86,023295%); wrong: 84 (13,976705%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model myFrench-ud.tagger -testFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3\" -verboseResults false\n",
    "! java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model myFrench-ud.tagger -testFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3\" -verboseResults false\n",
    "# précision de 87% sur les tags, 13% sur les phrases, 69.9% sur les mots inconnus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "def make_corpus(filename):\n",
    "    return ConllCorpusReader(\".\", filename, ('ignore', 'words', 'ignore', 'pos'), separator=\"\\t\")\n",
    "train_corpus = make_corpus(\"fr-ud-train.conllu3\")\n",
    "dev_corpus = make_corpus(\"fr-ud-dev.conllu3\")\n",
    "test_corpus = make_corpus(\"fr-ud-test.conllu3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Cesc chiffres sont-ils identiques à ceux obtenus pour `dev`et pour `test` à la fin de la Partie 1 ?  On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Corpus: 366371 14554\n",
      "Dev_Corpus: 36830 1478\n",
      "Test_Corpus: 10298 416\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "print(\"Train_Corpus:\", len(train_corpus.tagged_words()), len(train_corpus.tagged_sents()))\n",
    "print(\"Dev_Corpus:\", len(dev_corpus.tagged_words()), len(dev_corpus.tagged_sents()))\n",
    "print(\"Test_Corpus:\", len(test_corpus.tagged_words()), len(test_corpus.tagged_sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17eme phrase : [('Comprenant', 'VERB'), ('six', 'NUM'), ('sommets', 'NOUN'), ('dont', 'PRON'), ('un', 'DET'), ('point', 'NOUN'), ('culminant', 'VERB'), ('à', 'ADP'), ('2 001', 'NUM'), ('mètres', 'NOUN'), ('et', 'CCONJ'), ('une', 'DET'), ('arrivée', 'NOUN'), ('en', 'ADP'), ('altitude', 'NOUN'), (',', 'PUNCT'), (\"c'\", 'PRON'), ('est', 'AUX'), ('une', 'DET'), ('étape', 'NOUN'), ('typique', 'ADJ'), ('de', 'ADP'), ('montagne', 'NOUN'), ('.', 'PUNCT')]\n",
      "mots 1001 à 1050: [('le', 'DET'), ('nombre', 'NOUN'), ('de', 'ADP'), ('décès', 'NOUN'), ('enregistrés', 'VERB'), ('au', '_'), ('à', 'ADP'), ('le', 'DET'), ('cours', 'NOUN'), (\"d'\", 'ADP'), ('une', 'DET'), ('même', 'ADJ'), ('année', 'NOUN'), (',', 'PUNCT'), ('connaît', 'VERB'), ('une', 'DET'), ('forte', 'ADJ'), ('augmentation', 'NOUN'), (',', 'PUNCT'), ('puisque', 'SCONJ'), ('la', 'DET'), ('variation', 'NOUN'), ('annuelle', 'ADJ'), ('due', 'VERB'), ('au', '_'), ('à', 'ADP'), ('le', 'DET'), ('solde', 'NOUN'), ('naturel', 'ADJ'), ('passe', 'VERB'), ('de', 'ADP'), ('-1', 'NUM'), ('à', 'ADP'), ('-0,8', 'NUM'), ('.', 'PUNCT'), ('Il', 'PRON'), ('ne', 'ADV'), ('sera', 'AUX'), ('présent', 'ADJ'), ('que', 'ADV'), ('durant', 'ADP'), ('les', 'DET'), ('10', 'NUM'), ('premières', 'ADJ'), ('parties', 'NOUN'), ('.', 'PUNCT'), ('Les', 'DET'), ('capteurs', 'NOUN'), ('solaires', 'ADJ'), ('sous', 'ADP')]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "print(\"17eme phrase :\", dev_corpus.tagged_sents()[16])\n",
    "print(\"mots 1001 à 1050:\", dev_corpus.tagged_words()[1000:1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "import time\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.34821629524231\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "start = time.time()\n",
    "ptagger.train(train_corpus.tagged_sents(), \"./train_corpus.pickle\", 2)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule (en commentaires).\n",
    "# L'entrainement prend environ 44s\n",
    "# le fichier résultat pèse 5Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dev: 0.9631007330980179\n",
      "Accuracy on test: 0.9548456010875899\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "print(\"Accuracy on dev:\" ,ptagger.accuracy(dev_corpus.tagged_sents()))\n",
    "print(\"Accuracy on test:\" ,ptagger.accuracy(test_corpus.tagged_sents()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt | MaxEnt   | Avg Perceptron | \n",
    "|--------|--------|----------|---------------|\n",
    "| -      | fourni | entraîné | entraîné |\n",
    "| dev    |  88%   |   96%    |  96%  |\n",
    "| test   |  87%   |   96%    |  95%  |\n",
    "\n",
    "Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule.\n",
    "Après entrainement, les deux POS taggers ont une performance très proche. Pourtant, avec les options disponibles pour le tagger MaxEnt, on s'attendrait à ce qu'il ait une meilleure performance. Il se peut qu'il existe des paramètres parfaits permettant d'attendre une performance optimale, mais le temps de recherche de ces paramètres, et surtout le temps d'entrainement (10 minutes et plus) pour chaque essai, ne valent pas le peu de gain de performance. Au niveau du rapport perfomance/temps investi, le tagger Perceptron est de loin le meilleur (20X plus rapide pour la même performance!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le rendre via Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
