{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TAL_Lab04_word2vec_Christen_Mottier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installation des librairies"
      ],
      "metadata": {
        "id": "WVDAz2AAfXQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HvhELfne3YN",
        "outputId": "32b4e424-828c-47d0-cbde-ca133bc3ee98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==3.8.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader"
      ],
      "metadata": {
        "id": "ZFmukqz3f0kr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.a) Récupération du Corpus Google"
      ],
      "metadata": {
        "id": "GJQuzLfrftFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = gensim.downloader.load(\"word2vec-google-news-300\")\n",
        "w2v_vectors = w2v_model.wv\n",
        "del w2v_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATJIAFUBfpIC",
        "outputId": "f3c5de03-f5f3-4d16-d0dd-0067ccd89d5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save KeyedVectors on disk"
      ],
      "metadata": {
        "id": "cuw0GgboiIPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "6TqMG8lgfyhj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors.save('w2v_vectors.kv')"
      ],
      "metadata": {
        "id": "xy8XK-hniPYB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_w2v = KeyedVectors.load('w2v_vectors.kv', mmap='r')"
      ],
      "metadata": {
        "id": "1sQenutMjPUj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.b) Le notebook utilise 7.10Gb une fois le vecteur chargé"
      ],
      "metadata": {
        "id": "aq6FTiHAkQub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_w2v.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHfS4GUZjiNr",
        "outputId": "9b08ab6a-d22e-443d-d265-1d2e590ffd79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.c) La dimension de l'espace vectoriel est 300"
      ],
      "metadata": {
        "id": "nKPoWxdak_UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(reloaded_w2v.vocab))\n",
        "vocab = reloaded_w2v.vocab\n",
        "words = [\"shoulder\", \"bauble\", \"parrot\", \"nonplussed\", \"mischievous\", \"beguile\", \"otorhinolaryngologist\", \"epeolatry\", \"anatidaephobia\"]\n",
        "print([word in vocab for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuztdTe_jleD",
        "outputId": "5e75483d-5f4d-477f-a9d3-566efc0ac3d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n",
            "[True, True, True, True, True, True, False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.d) La taille du vocabulaire est 3'000'000"
      ],
      "metadata": {
        "id": "PL0ASQRYlM9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_w2v.similarity(\"rabbit\", \"carrot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqufnG14lJCT",
        "outputId": "f6ff8aa2-c9b8-4955-a653-17cdacba0903"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36306435"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.e) La distance est 0.637. Elle est calculé comme 1 moins la similarité.\n",
        "La similarité entre deux mot est le cosinus de l'angle entre leurs vecteurs."
      ],
      "metadata": {
        "id": "72upQWB2ouTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "         (\"astrophysicist\", \"spaceship\"),\n",
        "         (\"beer\", \"wine\"),\n",
        "         (\"progamming\", \"computer\"),\n",
        "         (\"programmer\", \"coder\"),\n",
        "         (\"cat\", \"animal\"),\n",
        "         (\"food\", \"steak\"),\n",
        "         (\"cactus\", \"flower\"),\n",
        "         (\"boy\", \"girl\"),\n",
        "         (\"moon\", \"chair\"),\n",
        "]\n",
        "[(w1, w2, reloaded_w2v.distance(w1,w2)) for (w1,w2) in pairs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dNLzP7Ooi0z",
        "outputId": "23b5fe06-976f-43ac-a3a8-f778541660a5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('astrophysicist', 'spaceship', 0.6500389277935028),\n",
              " ('beer', 'wine', 0.3782304525375366),\n",
              " ('progamming', 'computer', 0.8665198385715485),\n",
              " ('programmer', 'coder', 0.3886645436286926),\n",
              " ('cat', 'animal', 0.40923118591308594),\n",
              " ('food', 'steak', 0.6963566839694977),\n",
              " ('cactus', 'flower', 0.5169245898723602),\n",
              " ('boy', 'girl', 0.14567279815673828),\n",
              " ('moon', 'chair', 0.9386307448148727)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Globalement, notre intuition trouve les mots plus proches de la distance mesurée. Par exemple, on s'attend à ce que \"programming\" et \"computer\" soit relativement proche, mais ils sont en fait très éloignés, idem pour \"food\" et \"steak\"."
      ],
      "metadata": {
        "id": "9gcBdA0NrWoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opposed_pairs = [\n",
        "         (\"flammable\", \"inflammable\"),\n",
        "         (\"accelerate\", \"decelerate\"),\n",
        "         (\"free\", \"expensive\"),\n",
        "         (\"dead\", \"alive\"),\n",
        "         (\"strict\", \"chaotic\"),\n",
        "         (\"random\", \"ordered\"),\n",
        "         (\"water\", \"fire\"),\n",
        "         (\"water\", \"land\"),\n",
        "]\n",
        "[(w1, w2, reloaded_w2v.distance(w1,w2)) for (w1,w2) in opposed_pairs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSviVgchqV8y",
        "outputId": "53fa4d7e-23b2-4e49-bc10-eee644c4719c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('flammable', 'inflammable', 0.3406251072883606),\n",
              " ('accelerate', 'decelerate', 0.5433007180690765),\n",
              " ('free', 'expensive', 0.8415442407131195),\n",
              " ('dead', 'alive', 0.5353720188140869),\n",
              " ('strict', 'chaotic', 0.7622213512659073),\n",
              " ('random', 'ordered', 0.947737280279398),\n",
              " ('water', 'fire', 0.7728232890367508),\n",
              " ('water', 'land', 0.6596656739711761)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut voir que \"flammable\" et \"inflammable\" sont vraiment très proche. Cela vient sans aucun doute du fait qu'ils sont interchangeable dans la langue oral, même si à l'origine ils sont de sens opposé. On remarque également les couples \"accelerate\"-\"decelerate\" et \"dead\"-\"alive\" qui sont de sens opposés mais relativement proche. Ceci peut venir du faire que ces mots sont souvent interchangeables dans une phrase.\n",
        "C'est un défaut pour trouver des synonymes, mais une qualité pour regrouper les mots qui ont des sens similaires."
      ],
      "metadata": {
        "id": "Jg6HkHaJtLMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mm_word = \"bark\"\n",
        "word_with_same_meanings = [\"tree\", \"dog\"]\n",
        "[(w, reloaded_w2v.distance(mm_word, w)) for w in word_with_same_meanings]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5oNRDdrs4eO",
        "outputId": "8b97079f-a759-4169-c7cd-9ae33285d121"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tree', 0.5904216468334198), ('dog', 0.5834362804889679)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le model ne fait pas de différence entre les significations, et reste donc relativement éloignés de chacun des sens. Un humain à l'opposé associera un mot avec la signification la plus proche d'un autre, et réduira les distances entre eux."
      ],
      "metadata": {
        "id": "Ta6QCWccvf-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath\n",
        "reloaded_w2v.evaluate_word_pairs(datapath('wordsim353.tsv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGzzToaFuPYA",
        "outputId": "dd9284bd-abe0-4c95-b5d1-a819e624e626"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.6238773466616107, 1.7963237724171284e-39),\n",
              " SpearmanrResult(correlation=0.6589215888009288, pvalue=2.5346056459149263e-45),\n",
              " 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "woubxQmE24VQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}