{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HKiQmVpon_7"
      },
      "source": [
        "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\"/>\n",
        "\n",
        "# Cours TAL - Laboratoire 6\n",
        "# Classification\n",
        "\n",
        "**Objectif**\n",
        "\n",
        "L’objectif de ce labo est de réaliser des expériences de classification de documents sous NLTK avec le\n",
        "corpus de dépêches Reuters. Le labo est à effectuer en binôme. Le labo sera jugé sur la qualité des\n",
        "expériences et sur la discussion des différentes options explorées. Vous devez remettre un notebook\n",
        "Jupyter présentant vos choix, votre code, vos résultats et les discussions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Données\n",
        "les dépêches du corpus Reuters, tel qu’il est fourni par NLTK. Vous respecterez\n",
        "notamment la division en données d’entraînement (train) et données de test."
      ],
      "metadata": {
        "id": "UugdPGKxvup8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports et téléchargement du corpus\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "nltk.download('reuters')\n",
        "\n",
        "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora\n",
        "\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfWSduvkzL62",
        "outputId": "ef7ac6f5-12cd-448b-a334-d0e1e3bf9cd4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "Archive:  /root/nltk_data/corpora/reuters.zip\n",
            "replace /root/nltk_data/corpora/reuters/cats.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploration du corpus\n",
        "print(reuters.categories())\n",
        "print(len(reuters.fileids()))\n",
        "print(reuters.words(categories=['grain']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2JyLe9X0nZ8",
        "outputId": "771c5ee0-2b46-4efd-cc8c-2dd922bbeb06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n",
            "10788\n",
            "['CHINA', 'DAILY', 'SAYS', 'VERMIN', 'EAT', '7', '-', ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparation des documents d'entrainement et de test\n",
        "train_files= list(filter(lambda file: file.startswith(\"training\"),reuters.fileids()))\n",
        "test_files= list(filter(lambda file: file.startswith(\"test\"),reuters.fileids()))\n",
        "\n",
        "print(len(train_files))\n",
        "print(len(test_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WsvVZyQ1kJh",
        "outputId": "ccf3dd09-c23f-4d0e-881c-208ab17a93c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7769\n",
            "3019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hyper-paramètres \n",
        "veuillez étudier au moins deux hyperparamètres. Pour chacun, veuillez\n",
        "comparer au moins deux valeurs et indiquer laquelle fournit le meilleur score. Vous pourrez\n",
        "choisir parmi les hyperparamètres suivants :\n",
        "- options de prétraitement des textes : stopwords, lemmatisation, tout en minuscules.\n",
        "- options de représentation : présence/absence de mots indicateurs, nombre de mots\n",
        "indicateurs ; présence/absence/nombre de bigrammes, trigrammes ; autres traits :\n",
        "longueur de la dépêche, rapport tokens/types.\n",
        "- classifieurs et leurs paramètres : divers choix possibles (voir la documentation NLTK)."
      ],
      "metadata": {
        "id": "wpCnQbN4wA2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons choisis les hyperparamètres suivants : stopwords et présence/absence de trigrammes"
      ],
      "metadata": {
        "id": "HgXbuPAa3AdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# définir les fonctions pour les hyperparamètres\n",
        "from nltk.corpus import stopwords\n",
        "# stopwords\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(words):\n",
        "  return list([word for word in words if word not in stops])\n",
        "\n",
        "\n",
        "\n",
        "print(remove_stop_words(['Hello', 'this', 'is', 'Patrick']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXWoUE2120Nc",
        "outputId": "fc0a1706-b138-4937-fd6f-ff4cec13c6be"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Patrick']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Entraînement\n",
        "Veuillez définir et entraîner trois classifieurs binaires : chacun prédit si une dépêche est\n",
        "étiquetée ou non avec la catégorie respective. Le premier classifieur binaire sera pour\n",
        "l’étiquette ‘money-fx’, le deuxième concernera ‘grain’, et le troisième sera pour ‘nat-gas’."
      ],
      "metadata": {
        "id": "WTHnZQPvwDlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "labels = ['money-fx', 'grain', 'nat-gas']\n",
        "\n",
        "# Maybe separate respecting proportion :p\n",
        "def separate_list(the_list, train_rate= 0.8):\n",
        "  index = math.floor(len(the_list) * train_rate)\n",
        "  shuffle(the_list)\n",
        "  return (the_list[:index], the_list[index:])\n",
        "\n",
        "train_dev_set = {}\n",
        "for label in labels:\n",
        "  train_dev_set[label] = separate_list(train_files, train_rate=0.8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwD8znCO3UHN",
        "outputId": "21d07e29-396b-4ad9-c563-4f43aba3ede8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Optimisation\n",
        "Pour chacun des classifieurs, optimisez les hyperparamètres sans toucher aux données de test\n",
        "NLTK. Divisez les données d’entraînement NLTK en 80% train et 20% dev, et choisissez les\n",
        "options qui donnent les meilleurs scores sur dev."
      ],
      "metadata": {
        "id": "89uSP9HmwgUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Scores\n",
        "Veuillez donner les scores de rappel, précision et f-mesure de chacun des trois classifieurs,\n",
        "avec les meilleurs hyperparamètres, sur les données de test."
      ],
      "metadata": {
        "id": "-fMoAIDqwhTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Classifieur multi-classe\n",
        "Veuillez définir un quatrième classifieur multi-classe qui assigne une étiquette parmi quatre :\n",
        "les trois choisies ci-dessus plus la catégorie ‘other’. Vous devrez nettoyer les données, car un\n",
        "petit nombre de dépêches sont annotées avec plusieurs étiquettes : dans ce cas, gardez\n",
        "seulement la première."
      ],
      "metadata": {
        "id": "tdwUBRUCwz8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Score\n",
        "Veuillez donner les scores de rappel, précision et f-mesure de ce classifieur pour chacune des\n",
        "trois étiquettes choisies. Comment les scores se comparent-ils à ceux des trois classifieurs\n",
        "binaires ?"
      ],
      "metadata": {
        "id": "xDwngbz8w_iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Conclusion"
      ],
      "metadata": {
        "id": "c8y_eThExHdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l3xa2sRVv4Eq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TAL_Labo6_classification_Christen_Mottier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}